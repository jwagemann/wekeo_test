{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='../../img/ai4eo_logos.jpg' alt='Logos AI4EO MOOC' width='80%'></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.futurelearn.com/courses/artificial-intelligence-for-earth-monitoring/1/steps/1170987\"><< Back to FutureLearn</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of a sequential neural network for soil moisture prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>by Leonardo De Laurentiis, University of Tor Vergata, Rome, Italy</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch the video tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"center\"><iframe src=\"https://player.vimeo.com/video/510225048\" width=\"640\" height=\"360\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen align=\"middle\"></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<div align=\"center\"><iframe src=\"https://player.vimeo.com/video/510225048\" width=\"640\" height=\"360\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen align=\"middle\"></iframe></div>')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workflow will guide you through the different steps to train a `sequential neural network model` in order to predict soil moisture based on SAR backscatter and incidence angle information. The model is trained based on VH and VV backscatter information retrieved from an implementation of the [Integral Equation Model modified by Baghdadi (IEM-B)](https://www.mdpi.com/2073-4441/9/1/38).\n",
    "\n",
    "The IEM-B is a well-known inversion model which can simulate the backscattering and polarisation of SAR data based on ground-truth soil moisture values. The input data to the model were soil moisture values from the [International Soil Moisture Network (ISMN)](https://hess.copernicus.org/preprints/hess-2021-2/) and SAR incidence angles from 30 to 32.\n",
    "\n",
    "The `sequential neural network` learns how to invert from SAR backscatter and incidence angle information to predict soil moisture content. Backscatter and incidence angle information from a Sentinel-1 image and the associated soil moisture value from an ISMN station near Bordeaux, France (44.789900 N, -0.576500 W) serve for model validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine-Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow trains a [sequential neural network with Keras](https://keras.io/api/models/sequential/), which is a linear stack of layers. There are two ways to build Keras models:\n",
    "* in a `sequential` way and\n",
    "* a `functional` way.\n",
    "\n",
    "The `sequential` API allows you to create models in a sequential way, which means you add one layer after the other. A sequential model is applicable for most problems. Limitations of `sequential` models are that they do not allow you to create models that share layers or that have multiple inputs or outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workflow makes use of the .txt file [MOOC_IEM_Data](./MOOC_IEM_Data.txt). The file contains of a total of 268 rows and four columns. The first 264 rows contain the IEM-B model outputs (`VV- and VH-backscatter` values) of a sequence of `soil moisture values` ranging from 0.01 to 0.81 with a step of 0.025 and associated `incidence angles` ([30,32]). The first 264 rows are used to train the sequential model. \n",
    "\n",
    "The last four rows contain `VV- and VH-backscatter values, incidence angles` from Sentinel-1 images and associated measured `soil moisture values` from a location near Bordeaux, France ((44.789900 N, -0.576500 W) taken from the International Soil Moisture Network (ISMN).\n",
    "\n",
    "The columns are as follows: \n",
    "* Column 1 - `SAR VH backscattering values in dB`\n",
    "* Column 2 - `SAR VV backscattering values in dB`\n",
    "* Column 3 - `incidence angles in degrees`\n",
    "* Column 4 - `volumetric soil moisture content`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Evaluation of the Oh, Dubois and IEM Backscatter Models Using a Large Dataset of SAR Data and Experimental Soil Measurements](https://www.mdpi.com/2073-4441/9/1/38)\n",
    "* [International Soil Moisture Network (ISMN)](https://hess.copernicus.org/preprints/hess-2021-2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook outline\n",
    "* [1 - Load and prepare the input and output data for model training](#load_prepare)\n",
    "* [2 - Define and compile a sequential neural network model with Keras](#define_seq_model)\n",
    "* [3 - Training (fitting) of the sequential model](#sequential_fitting)\n",
    "* [4 - Evaluate model performance](#model_evaluation)\n",
    "* [5 - Predicting soil moisture with the trained sequential neural network](#soil_moisture_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='load_prepare'></a>1. Load and prepare the input and output data for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load the .txt file [MOOC_IEM_DATA.txt](./MOOC_IEM_DATA.txt). The file contains 268 rows and four columns. Each row contains a different sample. The dataset contains `SAR VH backscatter in dB`, `SAR VV backscatter in dB`, `incidence angle in degrees` and `volumetric soil moisture content`. The first 264 rows indicate the IEM-B model outputs, while the last four rows hold information from Sentinel-1 images and soil moisture values from a station of the ISMN.\n",
    "\n",
    "With the numpy function `loadtxt`, you can load a text file, by indicating the delimiter used in the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.11440881e+02, -3.64672855e+01,  3.00000000e+01,\n",
       "         1.00000000e-02],\n",
       "       [-8.76129310e+01, -2.36669363e+01,  3.00000000e+01,\n",
       "         3.50000000e-02],\n",
       "       [-8.15197821e+01, -2.01477266e+01,  3.00000000e+01,\n",
       "         6.00000000e-02],\n",
       "       ...,\n",
       "       [-1.93148527e+01, -1.36881897e+01,  3.03145447e+01,\n",
       "         1.53400000e-01],\n",
       "       [-1.65789782e+01, -1.33898071e+01,  3.03364582e+01,\n",
       "         1.13900000e-01],\n",
       "       [-2.01774177e+01, -1.21917423e+01,  4.05743599e+01,\n",
       "         1.06000000e-01]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.loadtxt('./MOOC_IEM_Data.txt', delimiter=',')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the loaded dataset in `input (X)` and `output (y)` variables. From the dataset file, the first three columns (`SAR VH backscattering values in dB`, `SAR VV backscattering values in dB` and `incidence angle in degrees`) serve as input (X) values.\n",
    "\n",
    "The fourth column of the dataset file contains values of `volumetric soil moisture content`, which serve as output (y) variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.11440881e+02, -3.64672855e+01,  3.00000000e+01],\n",
       "        [-8.76129310e+01, -2.36669363e+01,  3.00000000e+01],\n",
       "        [-8.15197821e+01, -2.01477266e+01,  3.00000000e+01],\n",
       "        [-7.83381680e+01, -1.82439517e+01,  3.00000000e+01],\n",
       "        [-7.62944843e+01, -1.69926284e+01,  3.00000000e+01],\n",
       "        [-7.48347295e+01, -1.60838488e+01,  3.00000000e+01],\n",
       "        [-7.37214435e+01, -1.53818334e+01,  3.00000000e+01],\n",
       "        [-7.28334817e+01, -1.48161135e+01,  3.00000000e+01],\n",
       "        [-7.21016652e+01, -1.43458828e+01,  3.00000000e+01],\n",
       "        [-7.14832120e+01, -1.39456095e+01,  3.00000000e+01],\n",
       "        [-7.09500391e+01, -1.35983659e+01,  3.00000000e+01],\n",
       "        [-7.04828348e+01, -1.32924097e+01,  3.00000000e+01],\n",
       "        [-7.00678137e+01, -1.30192944e+01,  3.00000000e+01],\n",
       "        [-6.96948291e+01, -1.27727596e+01,  3.00000000e+01],\n",
       "        [-6.93562188e+01, -1.25480485e+01,  3.00000000e+01],\n",
       "        [-6.90460719e+01, -1.23414705e+01,  3.00000000e+01],\n",
       "        [-6.87597487e+01, -1.21501135e+01,  3.00000000e+01],\n",
       "        [-6.84935588e+01, -1.19716508e+01,  3.00000000e+01],\n",
       "        [-6.82445453e+01, -1.18042108e+01,  3.00000000e+01],\n",
       "        [-6.80103425e+01, -1.16462923e+01,  3.00000000e+01],\n",
       "        [-6.77890897e+01, -1.14967139e+01,  3.00000000e+01],\n",
       "        [-6.75793913e+01, -1.13545938e+01,  3.00000000e+01],\n",
       "        [-6.73803161e+01, -1.12193541e+01,  3.00000000e+01],\n",
       "        [-6.71914255e+01, -1.10907443e+01,  3.00000000e+01],\n",
       "        [-6.70128071e+01, -1.09688687e+01,  3.00000000e+01],\n",
       "        [-6.68450638e+01, -1.08541825e+01,  3.00000000e+01],\n",
       "        [-6.66891897e+01, -1.07474104e+01,  3.00000000e+01],\n",
       "        [-6.65462844e+01, -1.06493509e+01,  3.00000000e+01],\n",
       "        [-6.64171554e+01, -1.05606038e+01,  3.00000000e+01],\n",
       "        [-6.63019844e+01, -1.04813365e+01,  3.00000000e+01],\n",
       "        [-6.62002255e+01, -1.04112113e+01,  3.00000000e+01],\n",
       "        [-6.61107545e+01, -1.03494851e+01,  3.00000000e+01],\n",
       "        [-6.60321376e+01, -1.02951937e+01,  3.00000000e+01],\n",
       "        [-9.57431478e+01, -2.99001049e+01,  3.00000000e+01],\n",
       "        [-7.19150711e+01, -1.71408250e+01,  3.00000000e+01],\n",
       "        [-6.58219085e+01, -1.36393662e+01,  3.00000000e+01],\n",
       "        [-6.26402987e+01, -1.17454163e+01,  3.00000000e+01],\n",
       "        [-6.05966234e+01, -1.05003255e+01,  3.00000000e+01],\n",
       "        [-5.91368778e+01, -9.59585226e+00,  3.00000000e+01],\n",
       "        [-5.80236006e+01, -8.89699193e+00,  3.00000000e+01],\n",
       "        [-5.71356473e+01, -8.33368466e+00,  3.00000000e+01],\n",
       "        [-5.64038386e+01, -7.86536002e+00,  3.00000000e+01],\n",
       "        [-5.57853927e+01, -7.46663198e+00,  3.00000000e+01],\n",
       "        [-5.52522265e+01, -7.12066756e+00,  3.00000000e+01],\n",
       "        [-5.47850284e+01, -6.81578890e+00,  3.00000000e+01],\n",
       "        [-5.43700133e+01, -6.54359460e+00,  3.00000000e+01],\n",
       "        [-5.39970342e+01, -6.29785710e+00,  3.00000000e+01],\n",
       "        [-5.36584291e+01, -6.07384367e+00,  3.00000000e+01],\n",
       "        [-5.33482872e+01, -5.86788210e+00,  3.00000000e+01],\n",
       "        [-5.30619687e+01, -5.67707441e+00,  3.00000000e+01],\n",
       "        [-5.27957833e+01, -5.49910481e+00,  3.00000000e+01],\n",
       "        [-5.25467742e+01, -5.33211041e+00,  3.00000000e+01],\n",
       "        [-5.23125755e+01, -5.17459675e+00,  3.00000000e+01],\n",
       "        [-5.20913267e+01, -5.02538805e+00,  3.00000000e+01],\n",
       "        [-5.18816322e+01, -4.88360660e+00,  3.00000000e+01],\n",
       "        [-5.16825608e+01, -4.74867752e+00,  3.00000000e+01],\n",
       "        [-5.14936740e+01, -4.62035266e+00,  3.00000000e+01],\n",
       "        [-5.13150591e+01, -4.49873749e+00,  3.00000000e+01],\n",
       "        [-5.11473191e+01, -4.38428793e+00,  3.00000000e+01],\n",
       "        [-5.09914482e+01, -4.27772857e+00,  3.00000000e+01],\n",
       "        [-5.08485458e+01, -4.17985817e+00,  3.00000000e+01],\n",
       "        [-5.07194195e+01, -4.09127685e+00,  3.00000000e+01],\n",
       "        [-5.06042509e+01, -4.01215341e+00,  3.00000000e+01],\n",
       "        [-5.05024941e+01, -3.94215208e+00,  3.00000000e+01],\n",
       "        [-5.04130251e+01, -3.88053227e+00,  3.00000000e+01],\n",
       "        [-5.03344098e+01, -3.82633243e+00,  3.00000000e+01],\n",
       "        [-8.88957244e+01, -2.71416499e+01,  3.00000000e+01],\n",
       "        [-6.50676083e+01, -1.44457180e+01,  3.00000000e+01],\n",
       "        [-5.89744415e+01, -1.09729343e+01,  3.00000000e+01],\n",
       "        [-5.57928330e+01, -9.09513577e+00,  3.00000000e+01],\n",
       "        [-5.37491603e+01, -7.86038776e+00,  3.00000000e+01],\n",
       "        [-5.22894175e+01, -6.96310347e+00,  3.00000000e+01],\n",
       "        [-5.11761432e+01, -6.26953194e+00,  3.00000000e+01],\n",
       "        [-5.02881925e+01, -5.71028113e+00,  3.00000000e+01],\n",
       "        [-4.95563861e+01, -5.24516875e+00,  3.00000000e+01],\n",
       "        [-4.89379425e+01, -4.84904964e+00,  3.00000000e+01],\n",
       "        [-4.84047784e+01, -4.50524821e+00,  3.00000000e+01],\n",
       "        [-4.79375823e+01, -4.20219374e+00,  3.00000000e+01],\n",
       "        [-4.75225690e+01, -3.93156037e+00,  3.00000000e+01],\n",
       "        [-4.71495916e+01, -3.68717520e+00,  3.00000000e+01],\n",
       "        [-4.68109881e+01, -3.46434615e+00,  3.00000000e+01],\n",
       "        [-4.65008478e+01, -3.25943173e+00,  3.00000000e+01],\n",
       "        [-4.62145307e+01, -3.06955768e+00,  3.00000000e+01],\n",
       "        [-4.59483468e+01, -2.89242669e+00,  3.00000000e+01],\n",
       "        [-4.56993390e+01, -2.72619046e+00,  3.00000000e+01],\n",
       "        [-4.54651417e+01, -2.56936607e+00,  3.00000000e+01],\n",
       "        [-4.52438942e+01, -2.42078688e+00,  3.00000000e+01],\n",
       "        [-4.50342009e+01, -2.27958224e+00,  3.00000000e+01],\n",
       "        [-4.48351306e+01, -2.14518257e+00,  3.00000000e+01],\n",
       "        [-4.46462449e+01, -2.01734338e+00,  3.00000000e+01],\n",
       "        [-4.44676311e+01, -1.89617234e+00,  3.00000000e+01],\n",
       "        [-4.42998921e+01, -1.78212628e+00,  3.00000000e+01],\n",
       "        [-4.41440223e+01, -1.67592991e+00,  3.00000000e+01],\n",
       "        [-4.40011208e+01, -1.57838207e+00,  3.00000000e+01],\n",
       "        [-4.38719954e+01, -1.49008371e+00,  3.00000000e+01],\n",
       "        [-4.37568275e+01, -1.41120577e+00,  3.00000000e+01],\n",
       "        [-4.36550714e+01, -1.34141590e+00,  3.00000000e+01],\n",
       "        [-4.35656029e+01, -1.27997778e+00,  3.00000000e+01],\n",
       "        [-4.34869882e+01, -1.22593430e+00,  3.00000000e+01],\n",
       "        [-8.53243395e+01, -2.48967891e+01,  3.00000000e+01],\n",
       "        [-6.14962082e+01, -1.22739043e+01,  3.00000000e+01],\n",
       "        [-5.54030397e+01, -8.83537997e+00,  3.00000000e+01],\n",
       "        [-5.22214318e+01, -6.97717360e+00,  3.00000000e+01],\n",
       "        [-5.01777600e+01, -5.75508060e+00,  3.00000000e+01],\n",
       "        [-4.87180184e+01, -4.86664199e+00,  3.00000000e+01],\n",
       "        [-4.76047451e+01, -4.17960384e+00,  3.00000000e+01],\n",
       "        [-4.67167954e+01, -3.62537883e+00,  3.00000000e+01],\n",
       "        [-4.59849900e+01, -3.16425537e+00,  3.00000000e+01],\n",
       "        [-4.53665473e+01, -2.77138187e+00,  3.00000000e+01],\n",
       "        [-4.48333840e+01, -2.43027526e+00,  3.00000000e+01],\n",
       "        [-4.43661886e+01, -2.12949635e+00,  3.00000000e+01],\n",
       "        [-4.39511760e+01, -1.86081214e+00,  3.00000000e+01],\n",
       "        [-4.35781993e+01, -1.61811721e+00,  3.00000000e+01],\n",
       "        [-4.32395965e+01, -1.39676962e+00,  3.00000000e+01],\n",
       "        [-4.29294567e+01, -1.19316592e+00,  3.00000000e+01],\n",
       "        [-4.26431402e+01, -1.00446121e+00,  3.00000000e+01],\n",
       "        [-4.23769568e+01, -8.28381128e-01,  3.00000000e+01],\n",
       "        [-4.21279496e+01, -6.63095452e-01,  3.00000000e+01],\n",
       "        [-4.18937527e+01, -5.07135640e-01,  3.00000000e+01],\n",
       "        [-4.16725057e+01, -3.59346362e-01,  3.00000000e+01],\n",
       "        [-4.14628129e+01, -2.18865779e-01,  3.00000000e+01],\n",
       "        [-4.12637431e+01, -8.51309005e-02,  3.00000000e+01],\n",
       "        [-4.10748578e+01,  4.20982174e-02,  3.00000000e+01],\n",
       "        [-4.08962444e+01,  1.62711234e-01,  3.00000000e+01],\n",
       "        [-4.07285059e+01,  2.76250183e-01,  3.00000000e+01],\n",
       "        [-4.05726364e+01,  3.81990235e-01,  3.00000000e+01],\n",
       "        [-4.04297353e+01,  4.79132514e-01,  3.00000000e+01],\n",
       "        [-4.03006102e+01,  5.67075030e-01,  3.00000000e+01],\n",
       "        [-4.01854426e+01,  6.45644188e-01,  3.00000000e+01],\n",
       "        [-4.00836868e+01,  7.15168029e-01,  3.00000000e+01],\n",
       "        [-3.99942185e+01,  7.76377561e-01,  3.00000000e+01],\n",
       "        [-3.99156040e+01,  8.30224307e-01,  3.00000000e+01],\n",
       "        [-1.11684411e+02, -3.65963842e+01,  3.20000000e+01],\n",
       "        [-8.78614598e+01, -2.37745911e+01,  3.20000000e+01],\n",
       "        [-8.17713747e+01, -2.02423740e+01,  3.20000000e+01],\n",
       "        [-7.85914426e+01, -1.83284163e+01,  3.20000000e+01],\n",
       "        [-7.65487097e+01, -1.70687238e+01,  3.20000000e+01],\n",
       "        [-7.50894957e+01, -1.61528722e+01,  3.20000000e+01],\n",
       "        [-7.39765054e+01, -1.54447546e+01,  3.20000000e+01],\n",
       "        [-7.30886853e+01, -1.48736802e+01,  3.20000000e+01],\n",
       "        [-7.23569095e+01, -1.43986848e+01,  3.20000000e+01],\n",
       "        [-7.17384290e+01, -1.39941216e+01,  3.20000000e+01],\n",
       "        [-7.12051816e+01, -1.36429759e+01,  3.20000000e+01],\n",
       "        [-7.07378692e+01, -1.33334389e+01,  3.20000000e+01],\n",
       "        [-7.03227160e+01, -1.30570116e+01,  3.20000000e+01],\n",
       "        [-6.99495816e+01, -1.28073918e+01,  3.20000000e+01],\n",
       "        [-6.96108081e+01, -1.25797886e+01,  3.20000000e+01],\n",
       "        [-6.93004879e+01, -1.23704834e+01,  3.20000000e+01],\n",
       "        [-6.90139834e+01, -1.21765411e+01,  3.20000000e+01],\n",
       "        [-6.87476060e+01, -1.19956153e+01,  3.20000000e+01],\n",
       "        [-6.84983997e+01, -1.18258183e+01,  3.20000000e+01],\n",
       "        [-6.82639997e+01, -1.16656356e+01,  3.20000000e+01],\n",
       "        [-6.80425461e+01, -1.15138756e+01,  3.20000000e+01],\n",
       "        [-6.78326438e+01, -1.13696489e+01,  3.20000000e+01],\n",
       "        [-6.76333626e+01, -1.12323738e+01,  3.20000000e+01],\n",
       "        [-6.74442650e+01, -1.11018004e+01,  3.20000000e+01],\n",
       "        [-6.72654402e+01, -1.09780387e+01,  3.20000000e+01],\n",
       "        [-6.70974933e+01, -1.08615551e+01,  3.20000000e+01],\n",
       "        [-6.69414217e+01, -1.07530898e+01,  3.20000000e+01],\n",
       "        [-6.67983278e+01, -1.06534584e+01,  3.20000000e+01],\n",
       "        [-6.66690222e+01, -1.05632746e+01,  3.20000000e+01],\n",
       "        [-6.65536887e+01, -1.04827129e+01,  3.20000000e+01],\n",
       "        [-6.64517821e+01, -1.04114336e+01,  3.20000000e+01],\n",
       "        [-6.63621782e+01, -1.03486845e+01,  3.20000000e+01],\n",
       "        [-6.62834420e+01, -1.02934881e+01,  3.20000000e+01],\n",
       "        [-9.59510135e+01, -2.99652278e+01,  3.20000000e+01],\n",
       "        [-7.21279303e+01, -1.71834954e+01,  3.20000000e+01],\n",
       "        [-6.60378309e+01, -1.36695959e+01,  3.20000000e+01],\n",
       "        [-6.28579032e+01, -1.17659577e+01,  3.20000000e+01],\n",
       "        [-6.08151790e+01, -1.05128697e+01,  3.20000000e+01],\n",
       "        [-5.93559746e+01, -9.60160593e+00,  3.20000000e+01],\n",
       "        [-5.82429935e+01, -8.89686186e+00,  3.20000000e+01],\n",
       "        [-5.73551822e+01, -8.32837372e+00,  3.20000000e+01],\n",
       "        [-5.66234146e+01, -7.85542574e+00,  3.20000000e+01],\n",
       "        [-5.60049416e+01, -7.45252483e+00,  3.20000000e+01],\n",
       "        [-5.54717012e+01, -7.10275703e+00,  3.20000000e+01],\n",
       "        [-5.50043954e+01, -6.79438185e+00,  3.20000000e+01],\n",
       "        [-5.45892484e+01, -6.51894846e+00,  3.20000000e+01],\n",
       "        [-5.42161197e+01, -6.27018963e+00,  3.20000000e+01],\n",
       "        [-5.38773516e+01, -6.04334034e+00,  3.20000000e+01],\n",
       "        [-5.35670366e+01, -5.83470167e+00,  3.20000000e+01],\n",
       "        [-5.32805371e+01, -5.64135347e+00,  3.20000000e+01],\n",
       "        [-5.30141644e+01, -5.46096132e+00,  3.20000000e+01],\n",
       "        [-5.27649627e+01, -5.29164678e+00,  3.20000000e+01],\n",
       "        [-5.25305671e+01, -5.13190264e+00,  3.20000000e+01],\n",
       "        [-5.23091176e+01, -4.98054308e+00,  3.20000000e+01],\n",
       "        [-5.20992195e+01, -4.83668333e+00,  3.20000000e+01],\n",
       "        [-5.18999422e+01, -4.69974495e+00,  3.20000000e+01],\n",
       "        [-5.17108485e+01, -4.56948051e+00,  3.20000000e+01],\n",
       "        [-5.15320273e+01, -4.44600125e+00,  3.20000000e+01],\n",
       "        [-5.13640840e+01, -4.32977430e+00,  3.20000000e+01],\n",
       "        [-5.12080156e+01, -4.22153979e+00,  3.20000000e+01],\n",
       "        [-5.10649248e+01, -4.12211352e+00,  3.20000000e+01],\n",
       "        [-5.09356221e+01, -4.03210968e+00,  3.20000000e+01],\n",
       "        [-5.08202911e+01, -3.95170404e+00,  3.20000000e+01],\n",
       "        [-5.07183868e+01, -3.88055920e+00,  3.20000000e+01],\n",
       "        [-5.06287849e+01, -3.81792570e+00,  3.20000000e+01],\n",
       "        [-5.05500504e+01, -3.76282873e+00,  3.20000000e+01],\n",
       "        [-8.90426674e+01, -2.71543792e+01,  3.20000000e+01],\n",
       "        [-6.52195423e+01, -1.44306375e+01,  3.20000000e+01],\n",
       "        [-5.91294383e+01, -1.09452137e+01,  3.20000000e+01],\n",
       "        [-5.59495120e+01, -9.05800517e+00,  3.20000000e+01],\n",
       "        [-5.39067906e+01, -7.81556334e+00,  3.20000000e+01],\n",
       "        [-5.24475892e+01, -6.91175210e+00,  3.20000000e+01],\n",
       "        [-5.13346111e+01, -6.21251683e+00,  3.20000000e+01],\n",
       "        [-5.04468025e+01, -5.64826831e+00,  3.20000000e+01],\n",
       "        [-4.97150375e+01, -5.17868627e+00,  3.20000000e+01],\n",
       "        [-4.90965670e+01, -4.77852461e+00,  3.20000000e+01],\n",
       "        [-4.85633288e+01, -4.43103151e+00,  3.20000000e+01],\n",
       "        [-4.80960251e+01, -4.12457730e+00,  3.20000000e+01],\n",
       "        [-4.76808800e+01, -3.85078948e+00,  3.20000000e+01],\n",
       "        [-4.73077531e+01, -3.60345768e+00,  3.20000000e+01],\n",
       "        [-4.69689868e+01, -3.37785919e+00,  3.20000000e+01],\n",
       "        [-4.66586734e+01, -3.17032722e+00,  3.20000000e+01],\n",
       "        [-4.63721755e+01, -2.97796635e+00,  3.20000000e+01],\n",
       "        [-4.61058042e+01, -2.79846155e+00,  3.20000000e+01],\n",
       "        [-4.58566039e+01, -2.62994964e+00,  3.20000000e+01],\n",
       "        [-4.56222097e+01, -2.47093553e+00,  3.20000000e+01],\n",
       "        [-4.54007616e+01, -2.32024296e+00,  3.20000000e+01],\n",
       "        [-4.51908648e+01, -2.17699460e+00,  3.20000000e+01],\n",
       "        [-4.49915888e+01, -2.04061757e+00,  3.20000000e+01],\n",
       "        [-4.48024962e+01, -1.91086826e+00,  3.20000000e+01],\n",
       "        [-4.46236762e+01, -1.78786021e+00,  3.20000000e+01],\n",
       "        [-4.44557340e+01, -1.67206145e+00,  3.20000000e+01],\n",
       "        [-4.42996668e+01, -1.56421226e+00,  3.20000000e+01],\n",
       "        [-4.41565769e+01, -1.46512845e+00,  3.20000000e+01],\n",
       "        [-4.40272751e+01, -1.37542508e+00,  3.20000000e+01],\n",
       "        [-4.39119448e+01, -1.29528017e+00,  3.20000000e+01],\n",
       "        [-4.38100413e+01, -1.22435996e+00,  3.20000000e+01],\n",
       "        [-4.37204400e+01, -1.16191948e+00,  3.20000000e+01],\n",
       "        [-4.36417061e+01, -1.10698863e+00,  3.20000000e+01],\n",
       "        [-8.53982110e+01, -2.49216573e+01,  3.20000000e+01],\n",
       "        [-6.15750695e+01, -1.22622559e+01,  3.20000000e+01],\n",
       "        [-5.54849637e+01, -8.81001617e+00,  3.20000000e+01],\n",
       "        [-5.23050379e+01, -6.94231457e+00,  3.20000000e+01],\n",
       "        [-5.02623176e+01, -5.71264382e+00,  3.20000000e+01],\n",
       "        [-4.88031174e+01, -4.81783189e+00,  3.20000000e+01],\n",
       "        [-4.76901405e+01, -4.12527955e+00,  3.20000000e+01],\n",
       "        [-4.68023330e+01, -3.56619191e+00,  3.20000000e+01],\n",
       "        [-4.60705690e+01, -3.10071804e+00,  3.20000000e+01],\n",
       "        [-4.54520994e+01, -2.70390670e+00,  3.20000000e+01],\n",
       "        [-4.49188620e+01, -2.35920052e+00,  3.20000000e+01],\n",
       "        [-4.44515591e+01, -2.05510322e+00,  3.20000000e+01],\n",
       "        [-4.40364148e+01, -1.78333682e+00,  3.20000000e+01],\n",
       "        [-4.36632887e+01, -1.53775982e+00,  3.20000000e+01],\n",
       "        [-4.33245230e+01, -1.31370083e+00,  3.20000000e+01],\n",
       "        [-4.30142103e+01, -1.10753204e+00,  3.20000000e+01],\n",
       "        [-4.27277130e+01, -9.16388206e-01,  3.20000000e+01],\n",
       "        [-4.24613423e+01, -7.37977857e-01,  3.20000000e+01],\n",
       "        [-4.22121426e+01, -5.70456479e-01,  3.20000000e+01],\n",
       "        [-4.19777489e+01, -4.12343760e-01,  3.20000000e+01],\n",
       "        [-4.17563014e+01, -2.62475145e-01,  3.20000000e+01],\n",
       "        [-4.15464050e+01, -1.19982363e-01,  3.20000000e+01],\n",
       "        [-4.13471295e+01,  1.57006687e-02,  3.20000000e+01],\n",
       "        [-4.11580374e+01,  1.44812876e-01,  3.20000000e+01],\n",
       "        [-4.09792179e+01,  2.67237980e-01,  3.20000000e+01],\n",
       "        [-4.08112761e+01,  3.82506820e-01,  3.20000000e+01],\n",
       "        [-4.06552093e+01,  4.89879054e-01,  3.20000000e+01],\n",
       "        [-4.05121198e+01,  5.88538835e-01,  3.20000000e+01],\n",
       "        [-4.03828183e+01,  6.77870094e-01,  3.20000000e+01],\n",
       "        [-4.02674884e+01,  7.57692041e-01,  3.20000000e+01],\n",
       "        [-4.01655851e+01,  8.28333967e-01,  3.20000000e+01],\n",
       "        [-4.00759841e+01,  8.90535295e-01,  3.20000000e+01],\n",
       "        [-3.99972504e+01,  9.45260293e-01,  3.20000000e+01],\n",
       "        [-1.65503581e+01, -7.04848606e+00,  3.03004856e+01],\n",
       "        [-1.93148527e+01, -1.36881897e+01,  3.03145447e+01],\n",
       "        [-1.65789782e+01, -1.33898071e+01,  3.03364582e+01],\n",
       "        [-2.01774177e+01, -1.21917423e+01,  4.05743599e+01]]),\n",
       " array([0.01  , 0.035 , 0.06  , 0.085 , 0.11  , 0.135 , 0.16  , 0.185 ,\n",
       "        0.21  , 0.235 , 0.26  , 0.285 , 0.31  , 0.335 , 0.36  , 0.385 ,\n",
       "        0.41  , 0.435 , 0.46  , 0.485 , 0.51  , 0.535 , 0.56  , 0.585 ,\n",
       "        0.61  , 0.635 , 0.66  , 0.685 , 0.71  , 0.735 , 0.76  , 0.785 ,\n",
       "        0.81  , 0.01  , 0.035 , 0.06  , 0.085 , 0.11  , 0.135 , 0.16  ,\n",
       "        0.185 , 0.21  , 0.235 , 0.26  , 0.285 , 0.31  , 0.335 , 0.36  ,\n",
       "        0.385 , 0.41  , 0.435 , 0.46  , 0.485 , 0.51  , 0.535 , 0.56  ,\n",
       "        0.585 , 0.61  , 0.635 , 0.66  , 0.685 , 0.71  , 0.735 , 0.76  ,\n",
       "        0.785 , 0.81  , 0.01  , 0.035 , 0.06  , 0.085 , 0.11  , 0.135 ,\n",
       "        0.16  , 0.185 , 0.21  , 0.235 , 0.26  , 0.285 , 0.31  , 0.335 ,\n",
       "        0.36  , 0.385 , 0.41  , 0.435 , 0.46  , 0.485 , 0.51  , 0.535 ,\n",
       "        0.56  , 0.585 , 0.61  , 0.635 , 0.66  , 0.685 , 0.71  , 0.735 ,\n",
       "        0.76  , 0.785 , 0.81  , 0.01  , 0.035 , 0.06  , 0.085 , 0.11  ,\n",
       "        0.135 , 0.16  , 0.185 , 0.21  , 0.235 , 0.26  , 0.285 , 0.31  ,\n",
       "        0.335 , 0.36  , 0.385 , 0.41  , 0.435 , 0.46  , 0.485 , 0.51  ,\n",
       "        0.535 , 0.56  , 0.585 , 0.61  , 0.635 , 0.66  , 0.685 , 0.71  ,\n",
       "        0.735 , 0.76  , 0.785 , 0.81  , 0.01  , 0.035 , 0.06  , 0.085 ,\n",
       "        0.11  , 0.135 , 0.16  , 0.185 , 0.21  , 0.235 , 0.26  , 0.285 ,\n",
       "        0.31  , 0.335 , 0.36  , 0.385 , 0.41  , 0.435 , 0.46  , 0.485 ,\n",
       "        0.51  , 0.535 , 0.56  , 0.585 , 0.61  , 0.635 , 0.66  , 0.685 ,\n",
       "        0.71  , 0.735 , 0.76  , 0.785 , 0.81  , 0.01  , 0.035 , 0.06  ,\n",
       "        0.085 , 0.11  , 0.135 , 0.16  , 0.185 , 0.21  , 0.235 , 0.26  ,\n",
       "        0.285 , 0.31  , 0.335 , 0.36  , 0.385 , 0.41  , 0.435 , 0.46  ,\n",
       "        0.485 , 0.51  , 0.535 , 0.56  , 0.585 , 0.61  , 0.635 , 0.66  ,\n",
       "        0.685 , 0.71  , 0.735 , 0.76  , 0.785 , 0.81  , 0.01  , 0.035 ,\n",
       "        0.06  , 0.085 , 0.11  , 0.135 , 0.16  , 0.185 , 0.21  , 0.235 ,\n",
       "        0.26  , 0.285 , 0.31  , 0.335 , 0.36  , 0.385 , 0.41  , 0.435 ,\n",
       "        0.46  , 0.485 , 0.51  , 0.535 , 0.56  , 0.585 , 0.61  , 0.635 ,\n",
       "        0.66  , 0.685 , 0.71  , 0.735 , 0.76  , 0.785 , 0.81  , 0.01  ,\n",
       "        0.035 , 0.06  , 0.085 , 0.11  , 0.135 , 0.16  , 0.185 , 0.21  ,\n",
       "        0.235 , 0.26  , 0.285 , 0.31  , 0.335 , 0.36  , 0.385 , 0.41  ,\n",
       "        0.435 , 0.46  , 0.485 , 0.51  , 0.535 , 0.56  , 0.585 , 0.61  ,\n",
       "        0.635 , 0.66  , 0.685 , 0.71  , 0.735 , 0.76  , 0.785 , 0.81  ,\n",
       "        0.0848, 0.1534, 0.1139, 0.106 ]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset[:, 0:3]\n",
    "y = dataset[:, 3]\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='normalisation_sm'></a>Normalisation of input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(Feature) Normalisation` is a technique often applied in Machine Learning. The goal of normalisation is to change the values of the numeric columns to a common scale, without distorting differences in the ranges of values. For Machine Learning, not every dataset requires normalisation. It is only required when features have different ranges or units. This is the case with the present input data, which are `VV backscatters (in dB)`, `VH backscatters (in dB)` and `incidence angles in degrees`.\n",
    "\n",
    "Scikitlearn's preprocessing library offers the function `minmax_scale()`, which normalizes the input values to a range from 0 to 1. This normalisation process is known as `unity-based normalisation` and is a very common normalisation process in Machine Learning.\n",
    "\n",
    "The normalised values range then from 0 to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00255986, 0.00343881, 0.        ],\n",
       "       [0.25302696, 0.34440281, 0.        ],\n",
       "       [0.31707499, 0.4381443 , 0.        ],\n",
       "       [0.35051847, 0.48885532, 0.        ],\n",
       "       [0.37200062, 0.52218692, 0.        ],\n",
       "       [0.38734481, 0.54639416, 0.        ],\n",
       "       [0.39904709, 0.56509381, 0.        ],\n",
       "       [0.40838089, 0.58016293, 0.        ],\n",
       "       [0.41607337, 0.59268851, 0.        ],\n",
       "       [0.42257423, 0.60335062, 0.        ],\n",
       "       [0.42817866, 0.61260018, 0.        ],\n",
       "       [0.43308967, 0.62074996, 0.        ],\n",
       "       [0.43745216, 0.62802496, 0.        ],\n",
       "       [0.44137278, 0.63459193, 0.        ],\n",
       "       [0.44493208, 0.64057758, 0.        ],\n",
       "       [0.44819218, 0.64608021, 0.        ],\n",
       "       [0.45120187, 0.6511774 , 0.        ],\n",
       "       [0.45399992, 0.65593113, 0.        ],\n",
       "       [0.45661742, 0.66039124, 0.        ],\n",
       "       [0.45907924, 0.66459774, 0.        ],\n",
       "       [0.46140493, 0.66858207, 0.        ],\n",
       "       [0.46360917, 0.67236773, 0.        ],\n",
       "       [0.46570175, 0.67597012, 0.        ],\n",
       "       [0.46768727, 0.67939591, 0.        ],\n",
       "       [0.46956481, 0.68264233, 0.        ],\n",
       "       [0.47132804, 0.68569723, 0.        ],\n",
       "       [0.47296651, 0.68854133, 0.        ],\n",
       "       [0.47446866, 0.69115335, 0.        ],\n",
       "       [0.475826  , 0.69351731, 0.        ],\n",
       "       [0.47703661, 0.69562876, 0.        ],\n",
       "       [0.47810625, 0.69749669, 0.        ],\n",
       "       [0.47904672, 0.6991409 , 0.        ],\n",
       "       [0.4798731 , 0.70058706, 0.        ],\n",
       "       [0.16756632, 0.17836936, 0.        ],\n",
       "       [0.41803475, 0.5182394 , 0.        ],\n",
       "       [0.48208292, 0.61150806, 0.        ],\n",
       "       [0.51552636, 0.66195736, 0.        ],\n",
       "       [0.53700842, 0.69512295, 0.        ],\n",
       "       [0.55235251, 0.71921548, 0.        ],\n",
       "       [0.56405471, 0.73783108, 0.        ],\n",
       "       [0.57338841, 0.75283595, 0.        ],\n",
       "       [0.58108081, 0.76531075, 0.        ],\n",
       "       [0.58758159, 0.7759317 , 0.        ],\n",
       "       [0.59318596, 0.78514719, 0.        ],\n",
       "       [0.5980969 , 0.79326827, 0.        ],\n",
       "       [0.60245933, 0.80051873, 0.        ],\n",
       "       [0.60637989, 0.80706446, 0.        ],\n",
       "       [0.60993913, 0.81303153, 0.        ],\n",
       "       [0.61319919, 0.81851774, 0.        ],\n",
       "       [0.61620882, 0.8236003 , 0.        ],\n",
       "       [0.61900682, 0.82834089, 0.        ],\n",
       "       [0.62162428, 0.83278914, 0.        ],\n",
       "       [0.62408605, 0.83698484, 0.        ],\n",
       "       [0.6264117 , 0.84095933, 0.        ],\n",
       "       [0.6286159 , 0.84473597, 0.        ],\n",
       "       [0.63070844, 0.84833009, 0.        ],\n",
       "       [0.63269392, 0.85174829, 0.        ],\n",
       "       [0.63457143, 0.85498776, 0.        ],\n",
       "       [0.63633462, 0.85803637, 0.        ],\n",
       "       [0.63797306, 0.8608748 , 0.        ],\n",
       "       [0.63947517, 0.86348178, 0.        ],\n",
       "       [0.64083248, 0.86584133, 0.        ],\n",
       "       [0.64204308, 0.86794895, 0.        ],\n",
       "       [0.64311269, 0.86981358, 0.        ],\n",
       "       [0.64405314, 0.87145495, 0.        ],\n",
       "       [0.64487951, 0.87289868, 0.        ],\n",
       "       [0.23954289, 0.25184657, 0.        ],\n",
       "       [0.49001174, 0.59002919, 0.        ],\n",
       "       [0.55405996, 0.68253403, 0.        ],\n",
       "       [0.58750338, 0.73255311, 0.        ],\n",
       "       [0.60898541, 0.7654432 , 0.        ],\n",
       "       [0.62432948, 0.78934424, 0.        ],\n",
       "       [0.63603164, 0.80781896, 0.        ],\n",
       "       [0.64536532, 0.82271577, 0.        ],\n",
       "       [0.65305769, 0.83510501, 0.        ],\n",
       "       [0.65955845, 0.84565647, 0.        ],\n",
       "       [0.66516279, 0.85481434, 0.        ],\n",
       "       [0.67007372, 0.86288683, 0.        ],\n",
       "       [0.67443612, 0.87009571, 0.        ],\n",
       "       [0.67835667, 0.87660542, 0.        ],\n",
       "       [0.68191589, 0.88254094, 0.        ],\n",
       "       [0.68517593, 0.88799926, 0.        ],\n",
       "       [0.68818555, 0.89305695, 0.        ],\n",
       "       [0.69098353, 0.8977752 , 0.        ],\n",
       "       [0.69360098, 0.90220325, 0.        ],\n",
       "       [0.69606274, 0.9063806 , 0.        ],\n",
       "       [0.69838838, 0.91033831, 0.        ],\n",
       "       [0.70059256, 0.91409959, 0.        ],\n",
       "       [0.70268509, 0.91767961, 0.        ],\n",
       "       [0.70467056, 0.92108487, 0.        ],\n",
       "       [0.70654805, 0.92431252, 0.        ],\n",
       "       [0.70831124, 0.92735037, 0.        ],\n",
       "       [0.70994966, 0.93017913, 0.        ],\n",
       "       [0.71145177, 0.93277752, 0.        ],\n",
       "       [0.71280907, 0.93512953, 0.        ],\n",
       "       [0.71401965, 0.93723061, 0.        ],\n",
       "       [0.71508926, 0.93908961, 0.        ],\n",
       "       [0.71602971, 0.94072614, 0.        ],\n",
       "       [0.71685606, 0.9421657 , 0.        ],\n",
       "       [0.27708345, 0.31164312, 0.        ],\n",
       "       [0.52755245, 0.64787998, 0.        ],\n",
       "       [0.59160069, 0.73947225, 0.        ],\n",
       "       [0.62504411, 0.78896945, 0.        ],\n",
       "       [0.64652613, 0.82152245, 0.        ],\n",
       "       [0.66187018, 0.84518786, 0.        ],\n",
       "       [0.67357233, 0.86348855, 0.        ],\n",
       "       [0.682906  , 0.87825149, 0.        ],\n",
       "       [0.69059836, 0.89053448, 0.        ],\n",
       "       [0.69709911, 0.90099948, 0.        ],\n",
       "       [0.70270345, 0.91008557, 0.        ],\n",
       "       [0.70761436, 0.91809744, 0.        ],\n",
       "       [0.71197676, 0.92525441, 0.        ],\n",
       "       [0.7158973 , 0.93171909, 0.        ],\n",
       "       [0.71945652, 0.93761515, 0.        ],\n",
       "       [0.72271655, 0.94303856, 0.        ],\n",
       "       [0.72572616, 0.9480651 , 0.        ],\n",
       "       [0.72852414, 0.95275536, 0.        ],\n",
       "       [0.73114158, 0.95715809, 0.        ],\n",
       "       [0.73360333, 0.96131241, 0.        ],\n",
       "       [0.73592897, 0.96524908, 0.        ],\n",
       "       [0.73813315, 0.96899107, 0.        ],\n",
       "       [0.74022567, 0.97255338, 0.        ],\n",
       "       [0.74221113, 0.97594239, 0.        ],\n",
       "       [0.74408862, 0.97915517, 0.        ],\n",
       "       [0.7458518 , 0.98217952, 0.        ],\n",
       "       [0.74749022, 0.98499613, 0.        ],\n",
       "       [0.74899233, 0.98758371, 0.        ],\n",
       "       [0.75034962, 0.98992625, 0.        ],\n",
       "       [0.75156021, 0.9920191 , 0.        ],\n",
       "       [0.75262981, 0.99387101, 0.        ],\n",
       "       [0.75357025, 0.99550146, 0.        ],\n",
       "       [0.75439661, 0.99693578, 0.        ],\n",
       "       [0.        , 0.        , 0.18913674],\n",
       "       [0.25041455, 0.3415352 , 0.18913674],\n",
       "       [0.31443038, 0.43562317, 0.18913674],\n",
       "       [0.34785618, 0.48660543, 0.18913674],\n",
       "       [0.36932833, 0.52015996, 0.18913674],\n",
       "       [0.38466684, 0.54455558, 0.18913674],\n",
       "       [0.39636602, 0.56341777, 0.18913674],\n",
       "       [0.40569832, 0.57862953, 0.18913674],\n",
       "       [0.41339037, 0.59128202, 0.18913674],\n",
       "       [0.41989152, 0.60205841, 0.18913674],\n",
       "       [0.42549674, 0.6114119 , 0.18913674],\n",
       "       [0.43040888, 0.61965707, 0.18913674],\n",
       "       [0.43477276, 0.62702028, 0.18913674],\n",
       "       [0.43869496, 0.63366943, 0.18913674],\n",
       "       [0.44225597, 0.63973211, 0.18913674],\n",
       "       [0.44551789, 0.64530739, 0.18913674],\n",
       "       [0.44852948, 0.65047345, 0.18913674],\n",
       "       [0.4513295 , 0.65529279, 0.18913674],\n",
       "       [0.45394903, 0.65981568, 0.18913674],\n",
       "       [0.45641292, 0.66408248, 0.18913674],\n",
       "       [0.45874073, 0.66812493, 0.18913674],\n",
       "       [0.46094711, 0.67196671, 0.18913674],\n",
       "       [0.46304185, 0.67562332, 0.18913674],\n",
       "       [0.46502955, 0.67910141, 0.18913674],\n",
       "       [0.46690926, 0.68239806, 0.18913674],\n",
       "       [0.46867463, 0.68550085, 0.18913674],\n",
       "       [0.47031518, 0.68839005, 0.18913674],\n",
       "       [0.47181931, 0.69104394, 0.18913674],\n",
       "       [0.4731785 , 0.69344617, 0.18913674],\n",
       "       [0.47439083, 0.6955921 , 0.18913674],\n",
       "       [0.47546202, 0.69749077, 0.18913674],\n",
       "       [0.47640389, 0.69916222, 0.18913674],\n",
       "       [0.47723152, 0.70063249, 0.18913674],\n",
       "       [0.16538134, 0.17663468, 0.18913674],\n",
       "       [0.41579728, 0.51710278, 0.18913674],\n",
       "       [0.47981326, 0.61070282, 0.18913674],\n",
       "       [0.51323902, 0.6614102 , 0.18913674],\n",
       "       [0.53471108, 0.69478881, 0.18913674],\n",
       "       [0.55004948, 0.71906222, 0.18913674],\n",
       "       [0.56174856, 0.73783455, 0.18913674],\n",
       "       [0.57108078, 0.75297742, 0.18913674],\n",
       "       [0.57877274, 0.76557537, 0.18913674],\n",
       "       [0.58527381, 0.77630748, 0.18913674],\n",
       "       [0.59087895, 0.78562427, 0.18913674],\n",
       "       [0.59579103, 0.79383849, 0.18913674],\n",
       "       [0.60015484, 0.80117523, 0.18913674],\n",
       "       [0.60407698, 0.80780144, 0.18913674],\n",
       "       [0.60763793, 0.81384405, 0.18913674],\n",
       "       [0.6108998 , 0.81940157, 0.18913674],\n",
       "       [0.61391134, 0.8245518 , 0.18913674],\n",
       "       [0.61671131, 0.82935693, 0.18913674],\n",
       "       [0.61933079, 0.83386697, 0.18913674],\n",
       "       [0.62179464, 0.83812209, 0.18913674],\n",
       "       [0.6241224 , 0.84215387, 0.18913674],\n",
       "       [0.62632874, 0.84598587, 0.18913674],\n",
       "       [0.62842344, 0.84963351, 0.18913674],\n",
       "       [0.63041109, 0.85310338, 0.18913674],\n",
       "       [0.63229077, 0.8563925 , 0.18913674],\n",
       "       [0.6340561 , 0.85948845, 0.18913674],\n",
       "       [0.63569661, 0.8623715 , 0.18913674],\n",
       "       [0.63720071, 0.86501993, 0.18913674],\n",
       "       [0.63855987, 0.86741737, 0.18913674],\n",
       "       [0.63977217, 0.86955914, 0.18913674],\n",
       "       [0.64084334, 0.87145423, 0.18913674],\n",
       "       [0.64178519, 0.87312261, 0.18913674],\n",
       "       [0.6426128 , 0.87459023, 0.18913674],\n",
       "       [0.23799831, 0.2515075 , 0.18913674],\n",
       "       [0.48841469, 0.59043089, 0.18913674],\n",
       "       [0.55243071, 0.68327243, 0.18913674],\n",
       "       [0.58585645, 0.73354216, 0.18913674],\n",
       "       [0.60732849, 0.76663719, 0.18913674],\n",
       "       [0.62266686, 0.79071209, 0.18913674],\n",
       "       [0.63436591, 0.80933768, 0.18913674],\n",
       "       [0.64369809, 0.82436761, 0.18913674],\n",
       "       [0.65139003, 0.83687591, 0.18913674],\n",
       "       [0.65789107, 0.84753505, 0.18913674],\n",
       "       [0.6634962 , 0.85679125, 0.18913674],\n",
       "       [0.66840825, 0.8649543 , 0.18913674],\n",
       "       [0.67277204, 0.87224721, 0.18913674],\n",
       "       [0.67669416, 0.87883541, 0.18913674],\n",
       "       [0.68025509, 0.8848447 , 0.18913674],\n",
       "       [0.68351695, 0.89037274, 0.18913674],\n",
       "       [0.68652847, 0.89549668, 0.18913674],\n",
       "       [0.68932842, 0.90027816, 0.18913674],\n",
       "       [0.69194789, 0.90476683, 0.18913674],\n",
       "       [0.69441172, 0.9090025 , 0.18913674],\n",
       "       [0.69673947, 0.91301651, 0.18913674],\n",
       "       [0.69894579, 0.91683223, 0.18913674],\n",
       "       [0.70104048, 0.92046492, 0.18913674],\n",
       "       [0.70302812, 0.92392106, 0.18913674],\n",
       "       [0.70490779, 0.92719764, 0.18913674],\n",
       "       [0.70667311, 0.93028218, 0.18913674],\n",
       "       [0.70831361, 0.93315496, 0.18913674],\n",
       "       [0.70981769, 0.93579427, 0.18913674],\n",
       "       [0.71117685, 0.9381837 , 0.18913674],\n",
       "       [0.71238914, 0.94031853, 0.18913674],\n",
       "       [0.7134603 , 0.94220764, 0.18913674],\n",
       "       [0.71440214, 0.94387087, 0.18913674],\n",
       "       [0.71522975, 0.94533407, 0.18913674],\n",
       "       [0.27630695, 0.3109807 , 0.18913674],\n",
       "       [0.5267235 , 0.64819026, 0.18913674],\n",
       "       [0.59073955, 0.74014787, 0.18913674],\n",
       "       [0.62416528, 0.78989799, 0.18913674],\n",
       "       [0.6456373 , 0.82265284, 0.18913674],\n",
       "       [0.66097566, 0.84648802, 0.18913674],\n",
       "       [0.6726747 , 0.8649356 , 0.18913674],\n",
       "       [0.68200687, 0.87982806, 0.18913674],\n",
       "       [0.6896988 , 0.89222693, 0.18913674],\n",
       "       [0.69619983, 0.90279683, 0.18913674],\n",
       "       [0.70180495, 0.91197879, 0.18913674],\n",
       "       [0.70671699, 0.92007906, 0.18913674],\n",
       "       [0.71108078, 0.92731812, 0.18913674],\n",
       "       [0.71500288, 0.93385958, 0.18913674],\n",
       "       [0.71856381, 0.93982786, 0.18913674],\n",
       "       [0.72182566, 0.94531959, 0.18913674],\n",
       "       [0.72483717, 0.95041111, 0.18913674],\n",
       "       [0.72763712, 0.95516344, 0.18913674],\n",
       "       [0.73025658, 0.95962572, 0.18913674],\n",
       "       [0.73272041, 0.96383738, 0.18913674],\n",
       "       [0.73504815, 0.96782945, 0.18913674],\n",
       "       [0.73725447, 0.97162504, 0.18913674],\n",
       "       [0.73934915, 0.97523924, 0.18913674],\n",
       "       [0.74133679, 0.97867841, 0.18913674],\n",
       "       [0.74321645, 0.98193946, 0.18913674],\n",
       "       [0.74498177, 0.98500989, 0.18913674],\n",
       "       [0.74662226, 0.98786997, 0.18913674],\n",
       "       [0.74812634, 0.99049798, 0.18913674],\n",
       "       [0.74948549, 0.9928775 , 0.18913674],\n",
       "       [0.75069778, 0.99500373, 0.18913674],\n",
       "       [0.75176894, 0.99688542, 0.18913674],\n",
       "       [0.75271078, 0.99854229, 0.18913674],\n",
       "       [0.75353838, 1.        , 0.18913674],\n",
       "       [1.        , 0.78706989, 0.02841644],\n",
       "       [0.97094106, 0.61020754, 0.02974598],\n",
       "       [0.99969916, 0.61815558, 0.0318183 ],\n",
       "       [0.96187422, 0.65006854, 1.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_X = preprocessing.minmax_scale(X, feature_range=(0, 1))\n",
    "preprocessed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='split_training_test'></a>Split input data into training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, you want to split the input data into training and test data. \n",
    "\n",
    "As a first step, let us define a variable called `iem_samples` which holds the number of `integral equation model (IEM)` samples (264). This variable helps you to split the input (X) data into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iem_samples = dataset.shape[0]-4\n",
    "iem_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the variable defined in the previous step, you can split the normalised input (X) and output (y) data into training and test samples. You want to use the 264 IEM_B samples for training and the four samples based on Sentinel-1 images as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_S1 = preprocessed_X[iem_samples:]\n",
    "preprocessed_X_iem = preprocessed_X[:iem_samples]\n",
    "\n",
    "test_y_S1 = y[iem_samples:]\n",
    "y_iem = y[:iem_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step, you want to `random shuffle` the data. By `random shuffling` the data, you de-correlate potential correlation or a human-induced ordering of the input (X) and output (y) data.\n",
    "\n",
    "In order to random shuffle the data, you first create a list of integers with 264 entries with `np.arange()`, indicating the index values of a Python list. Then, you randomly shuffle the list of index values with `np.random.shuffle()`.\n",
    "\n",
    "The randomly shuffled list of index values can then be applied to the training input (`preprocessed_X_iem`) and training output (`y_iem`) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.arange(iem_samples)\n",
    "np.random.shuffle(s)\n",
    "preprocessed_X_shuffled = preprocessed_X_iem[s]\n",
    "y_shuffled = y_iem[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='split_2'></a>Split training data into training and test data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step splits the training data into two subsets: \n",
    "* `train_X` / `train_y` --> 70% of the training data\n",
    "* `test_X` / `test_y` --> 30% of the training data. \n",
    "\n",
    "The first 185 entries (70% of 264) are used for training the model and the remaining data are used for testing. You generate training and testing subsets originating from `preprocessed_X_shuffled` (input) and `y_shuffled` (output) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train_perc = 0.7\n",
    "n_train = round(preprocessed_X_shuffled.shape[0] * n_train_perc)\n",
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185,\n",
       " array([[0.67277204, 0.87224721, 0.18913674],\n",
       "        [0.64405314, 0.87145495, 0.        ],\n",
       "        [0.682906  , 0.87825149, 0.        ],\n",
       "        [0.68351695, 0.89037274, 0.18913674],\n",
       "        [0.62179464, 0.83812209, 0.18913674],\n",
       "        [0.71500288, 0.93385958, 0.18913674],\n",
       "        [0.60015484, 0.80117523, 0.18913674],\n",
       "        [0.6634962 , 0.85679125, 0.18913674],\n",
       "        [0.41579728, 0.51710278, 0.18913674],\n",
       "        [0.46690926, 0.68239806, 0.18913674],\n",
       "        [0.70059256, 0.91409959, 0.        ],\n",
       "        [0.61319919, 0.81851774, 0.        ],\n",
       "        [0.25041455, 0.3415352 , 0.18913674],\n",
       "        [0.60993913, 0.81303153, 0.        ],\n",
       "        [0.68517593, 0.88799926, 0.        ],\n",
       "        [0.23799831, 0.2515075 , 0.18913674],\n",
       "        [0.72182566, 0.94531959, 0.18913674],\n",
       "        [0.40569832, 0.57862953, 0.18913674],\n",
       "        [0.31443038, 0.43562317, 0.18913674],\n",
       "        [0.70667311, 0.93028218, 0.18913674],\n",
       "        [0.6726747 , 0.8649356 , 0.18913674],\n",
       "        [0.66840825, 0.8649543 , 0.18913674],\n",
       "        [0.61900682, 0.82834089, 0.        ],\n",
       "        [0.56405471, 0.73783108, 0.        ],\n",
       "        [0.5980969 , 0.79326827, 0.        ],\n",
       "        [0.6340561 , 0.85948845, 0.18913674],\n",
       "        [0.74408862, 0.97915517, 0.        ],\n",
       "        [0.75271078, 0.99854229, 0.18913674],\n",
       "        [0.5267235 , 0.64819026, 0.18913674],\n",
       "        [0.25302696, 0.34440281, 0.        ],\n",
       "        [0.16538134, 0.17663468, 0.18913674],\n",
       "        [0.44551789, 0.64530739, 0.18913674],\n",
       "        [0.68200687, 0.87982806, 0.18913674],\n",
       "        [0.4798731 , 0.70058706, 0.        ],\n",
       "        [0.67669416, 0.87883541, 0.18913674],\n",
       "        [0.70268509, 0.91767961, 0.        ],\n",
       "        [0.45394903, 0.65981568, 0.18913674],\n",
       "        [0.63041109, 0.85310338, 0.18913674],\n",
       "        [0.6108998 , 0.81940157, 0.18913674],\n",
       "        [0.47132804, 0.68569723, 0.        ],\n",
       "        [0.75262981, 0.99387101, 0.        ],\n",
       "        [0.46360917, 0.67236773, 0.        ],\n",
       "        [0.57108078, 0.75297742, 0.18913674],\n",
       "        [0.71508926, 0.93908961, 0.        ],\n",
       "        [0.60407698, 0.80780144, 0.18913674],\n",
       "        [0.74662226, 0.98786997, 0.18913674],\n",
       "        [0.63457143, 0.85498776, 0.        ],\n",
       "        [0.42549674, 0.6114119 , 0.18913674],\n",
       "        [0.41989152, 0.60205841, 0.18913674],\n",
       "        [0.64204308, 0.86794895, 0.        ],\n",
       "        [0.70104048, 0.92046492, 0.18913674],\n",
       "        [0.        , 0.        , 0.18913674],\n",
       "        [0.75069778, 0.99500373, 0.18913674],\n",
       "        [0.73813315, 0.96899107, 0.        ],\n",
       "        [0.47296651, 0.68854133, 0.        ],\n",
       "        [0.48208292, 0.61150806, 0.        ],\n",
       "        [0.58758159, 0.7759317 , 0.        ],\n",
       "        [0.74812634, 0.99049798, 0.18913674],\n",
       "        [0.44852948, 0.65047345, 0.18913674],\n",
       "        [0.63855987, 0.86741737, 0.18913674],\n",
       "        [0.27708345, 0.31164312, 0.        ],\n",
       "        [0.31707499, 0.4381443 , 0.        ],\n",
       "        [0.62408605, 0.83698484, 0.        ],\n",
       "        [0.45661742, 0.66039124, 0.        ],\n",
       "        [0.7158973 , 0.93171909, 0.        ],\n",
       "        [0.64652613, 0.82152245, 0.        ],\n",
       "        [0.49001174, 0.59002919, 0.        ],\n",
       "        [0.70654805, 0.92431252, 0.        ],\n",
       "        [0.46502955, 0.67910141, 0.18913674],\n",
       "        [0.58585645, 0.73354216, 0.18913674],\n",
       "        [0.71117685, 0.9381837 , 0.18913674],\n",
       "        [0.57877274, 0.76557537, 0.18913674],\n",
       "        [0.40838089, 0.58016293, 0.        ],\n",
       "        [0.46304185, 0.67562332, 0.18913674],\n",
       "        [0.41803475, 0.5182394 , 0.        ],\n",
       "        [0.46956481, 0.68264233, 0.        ],\n",
       "        [0.72483717, 0.95041111, 0.18913674],\n",
       "        [0.71401965, 0.93723061, 0.        ],\n",
       "        [0.47703661, 0.69562876, 0.        ],\n",
       "        [0.63633462, 0.85803637, 0.        ],\n",
       "        [0.56174856, 0.73783455, 0.18913674],\n",
       "        [0.74022567, 0.97255338, 0.        ],\n",
       "        [0.67007372, 0.86288683, 0.        ],\n",
       "        [0.64487951, 0.87289868, 0.        ],\n",
       "        [0.38734481, 0.54639416, 0.        ],\n",
       "        [0.74749022, 0.98499613, 0.        ],\n",
       "        [0.73504815, 0.96782945, 0.18913674],\n",
       "        [0.69194789, 0.90476683, 0.18913674],\n",
       "        [0.69606274, 0.9063806 , 0.        ],\n",
       "        [0.60245933, 0.80051873, 0.        ],\n",
       "        [0.35051847, 0.48885532, 0.        ],\n",
       "        [0.23954289, 0.25184657, 0.        ],\n",
       "        [0.74948549, 0.9928775 , 0.18913674],\n",
       "        [0.71856381, 0.93982786, 0.18913674],\n",
       "        [0.65139003, 0.83687591, 0.18913674],\n",
       "        [0.68025509, 0.8848447 , 0.18913674],\n",
       "        [0.71945652, 0.93761515, 0.        ],\n",
       "        [0.70302812, 0.92392106, 0.18913674],\n",
       "        [0.68652847, 0.89549668, 0.18913674],\n",
       "        [0.16756632, 0.17836936, 0.        ],\n",
       "        [0.63797306, 0.8608748 , 0.        ],\n",
       "        [0.41339037, 0.59128202, 0.18913674],\n",
       "        [0.69709911, 0.90099948, 0.        ],\n",
       "        [0.70490779, 0.92719764, 0.18913674],\n",
       "        [0.44137278, 0.63459193, 0.        ],\n",
       "        [0.58527381, 0.77630748, 0.18913674],\n",
       "        [0.59579103, 0.79383849, 0.18913674],\n",
       "        [0.70981769, 0.93579427, 0.18913674],\n",
       "        [0.67835667, 0.87660542, 0.        ],\n",
       "        [0.60763793, 0.81384405, 0.18913674],\n",
       "        [0.64178519, 0.87312261, 0.18913674],\n",
       "        [0.63229077, 0.8563925 , 0.18913674],\n",
       "        [0.70467056, 0.92108487, 0.        ],\n",
       "        [0.42817866, 0.61260018, 0.        ],\n",
       "        [0.43869496, 0.63366943, 0.18913674],\n",
       "        [0.63269392, 0.85174829, 0.        ],\n",
       "        [0.61933079, 0.83386697, 0.18913674],\n",
       "        [0.74221113, 0.97594239, 0.        ],\n",
       "        [0.53471108, 0.69478881, 0.18913674],\n",
       "        [0.45399992, 0.65593113, 0.        ],\n",
       "        [0.73360333, 0.96131241, 0.        ],\n",
       "        [0.71197676, 0.92525441, 0.        ],\n",
       "        [0.59087895, 0.78562427, 0.18913674],\n",
       "        [0.61671131, 0.82935693, 0.18913674],\n",
       "        [0.59073955, 0.74014787, 0.18913674],\n",
       "        [0.53700842, 0.69512295, 0.        ],\n",
       "        [0.63977217, 0.86955914, 0.18913674],\n",
       "        [0.75357025, 0.99550146, 0.        ],\n",
       "        [0.46570175, 0.67597012, 0.        ],\n",
       "        [0.62416528, 0.78989799, 0.18913674],\n",
       "        [0.43040888, 0.61965707, 0.18913674],\n",
       "        [0.63436591, 0.80933768, 0.18913674],\n",
       "        [0.69619983, 0.90279683, 0.18913674],\n",
       "        [0.75034962, 0.98992625, 0.        ],\n",
       "        [0.36932833, 0.52015996, 0.18913674],\n",
       "        [0.6426128 , 0.87459023, 0.18913674],\n",
       "        [0.47640389, 0.69916222, 0.18913674],\n",
       "        [0.6896988 , 0.89222693, 0.18913674],\n",
       "        [0.71108078, 0.92731812, 0.18913674],\n",
       "        [0.63603164, 0.80781896, 0.        ],\n",
       "        [0.73934915, 0.97523924, 0.18913674],\n",
       "        [0.73272041, 0.96383738, 0.18913674],\n",
       "        [0.47810625, 0.69749669, 0.        ],\n",
       "        [0.55243071, 0.68327243, 0.18913674],\n",
       "        [0.58750338, 0.73255311, 0.        ],\n",
       "        [0.73025658, 0.95962572, 0.18913674],\n",
       "        [0.55004948, 0.71906222, 0.18913674],\n",
       "        [0.69838838, 0.91033831, 0.        ],\n",
       "        [0.71145177, 0.93277752, 0.        ],\n",
       "        [0.44819218, 0.64608021, 0.        ],\n",
       "        [0.71522975, 0.94533407, 0.18913674],\n",
       "        [0.74133679, 0.97867841, 0.18913674],\n",
       "        [0.62162428, 0.83278914, 0.        ],\n",
       "        [0.6456373 , 0.82265284, 0.18913674],\n",
       "        [0.59318596, 0.78514719, 0.        ],\n",
       "        [0.46140493, 0.66858207, 0.        ],\n",
       "        [0.6264117 , 0.84095933, 0.        ],\n",
       "        [0.47439083, 0.6955921 , 0.18913674],\n",
       "        [0.38466684, 0.54455558, 0.18913674],\n",
       "        [0.57338841, 0.75283595, 0.        ],\n",
       "        [0.51552636, 0.66195736, 0.        ],\n",
       "        [0.66516279, 0.85481434, 0.        ],\n",
       "        [0.46867463, 0.68550085, 0.18913674],\n",
       "        [0.71280907, 0.93512953, 0.        ],\n",
       "        [0.69894579, 0.91683223, 0.18913674],\n",
       "        [0.55405996, 0.68253403, 0.        ],\n",
       "        [0.69098353, 0.8977752 , 0.        ],\n",
       "        [0.51323902, 0.6614102 , 0.18913674],\n",
       "        [0.63070844, 0.84833009, 0.        ],\n",
       "        [0.69673947, 0.91301651, 0.18913674],\n",
       "        [0.65955845, 0.84565647, 0.        ],\n",
       "        [0.61391134, 0.8245518 , 0.18913674],\n",
       "        [0.7458518 , 0.98217952, 0.        ],\n",
       "        [0.60637989, 0.80706446, 0.        ],\n",
       "        [0.62504411, 0.78896945, 0.        ],\n",
       "        [0.62842344, 0.84963351, 0.18913674],\n",
       "        [0.71602971, 0.94072614, 0.        ],\n",
       "        [0.66097566, 0.84648802, 0.18913674],\n",
       "        [0.70831124, 0.92735037, 0.        ],\n",
       "        [0.64536532, 0.82271577, 0.        ],\n",
       "        [0.70761436, 0.91809744, 0.        ],\n",
       "        [0.62432948, 0.78934424, 0.        ],\n",
       "        [0.61620882, 0.8236003 , 0.        ],\n",
       "        [0.4513295 , 0.65529279, 0.18913674],\n",
       "        [0.70831361, 0.93315496, 0.18913674]]),\n",
       " array([[0.75156021, 0.9920191 , 0.        ],\n",
       "        [0.62266686, 0.79071209, 0.18913674],\n",
       "        [0.70180495, 0.91197879, 0.18913674],\n",
       "        [0.47546202, 0.69749077, 0.18913674],\n",
       "        [0.70671699, 0.92007906, 0.18913674],\n",
       "        [0.34785618, 0.48660543, 0.18913674],\n",
       "        [0.75439661, 0.99693578, 0.        ],\n",
       "        [0.45907924, 0.66459774, 0.        ],\n",
       "        [0.41607337, 0.59268851, 0.        ],\n",
       "        [0.65789107, 0.84753505, 0.18913674],\n",
       "        [0.68191589, 0.88254094, 0.        ],\n",
       "        [0.63720071, 0.86501993, 0.18913674],\n",
       "        [0.73725447, 0.97162504, 0.18913674],\n",
       "        [0.44493208, 0.64057758, 0.        ],\n",
       "        [0.63947517, 0.86348178, 0.        ],\n",
       "        [0.48841469, 0.59043089, 0.18913674],\n",
       "        [0.72572616, 0.9480651 , 0.        ],\n",
       "        [0.47446866, 0.69115335, 0.        ],\n",
       "        [0.7134603 , 0.94220764, 0.18913674],\n",
       "        [0.39636602, 0.56341777, 0.18913674],\n",
       "        [0.43477276, 0.62702028, 0.18913674],\n",
       "        [0.43308967, 0.62074996, 0.        ],\n",
       "        [0.6241224 , 0.84215387, 0.18913674],\n",
       "        [0.59160069, 0.73947225, 0.        ],\n",
       "        [0.64084334, 0.87145423, 0.18913674],\n",
       "        [0.75176894, 0.99688542, 0.18913674],\n",
       "        [0.4731785 , 0.69344617, 0.18913674],\n",
       "        [0.68818555, 0.89305695, 0.        ],\n",
       "        [0.66187018, 0.84518786, 0.        ],\n",
       "        [0.72852414, 0.95275536, 0.        ],\n",
       "        [0.45120187, 0.6511774 , 0.        ],\n",
       "        [0.64311269, 0.86981358, 0.        ],\n",
       "        [0.27630695, 0.3109807 , 0.18913674],\n",
       "        [0.63569661, 0.8623715 , 0.18913674],\n",
       "        [0.55235251, 0.71921548, 0.        ],\n",
       "        [0.74498177, 0.98500989, 0.18913674],\n",
       "        [0.74899233, 0.98758371, 0.        ],\n",
       "        [0.58108081, 0.76531075, 0.        ],\n",
       "        [0.70270345, 0.91008557, 0.        ],\n",
       "        [0.72271655, 0.94303856, 0.        ],\n",
       "        [0.47904672, 0.6991409 , 0.        ],\n",
       "        [0.47181931, 0.69104394, 0.18913674],\n",
       "        [0.44225597, 0.63973211, 0.18913674],\n",
       "        [0.47723152, 0.70063249, 0.18913674],\n",
       "        [0.65305769, 0.83510501, 0.        ],\n",
       "        [0.00255986, 0.00343881, 0.        ],\n",
       "        [0.72763712, 0.95516344, 0.18913674],\n",
       "        [0.71440214, 0.94387087, 0.18913674],\n",
       "        [0.46768727, 0.67939591, 0.        ],\n",
       "        [0.73592897, 0.96524908, 0.        ],\n",
       "        [0.46094711, 0.67196671, 0.18913674],\n",
       "        [0.45641292, 0.66408248, 0.18913674],\n",
       "        [0.37200062, 0.52218692, 0.        ],\n",
       "        [0.6286159 , 0.84473597, 0.        ],\n",
       "        [0.52755245, 0.64787998, 0.        ],\n",
       "        [0.75353838, 1.        , 0.18913674],\n",
       "        [0.64083248, 0.86584133, 0.        ],\n",
       "        [0.475826  , 0.69351731, 0.        ],\n",
       "        [0.60898541, 0.7654432 , 0.        ],\n",
       "        [0.47031518, 0.68839005, 0.18913674],\n",
       "        [0.67357233, 0.86348855, 0.        ],\n",
       "        [0.68932842, 0.90027816, 0.18913674],\n",
       "        [0.42257423, 0.60335062, 0.        ],\n",
       "        [0.69059836, 0.89053448, 0.        ],\n",
       "        [0.74321645, 0.98193946, 0.18913674],\n",
       "        [0.71685606, 0.9421657 , 0.        ],\n",
       "        [0.69360098, 0.90220325, 0.        ],\n",
       "        [0.64369809, 0.82436761, 0.18913674],\n",
       "        [0.47981326, 0.61070282, 0.18913674],\n",
       "        [0.39904709, 0.56509381, 0.        ],\n",
       "        [0.67443612, 0.87009571, 0.        ],\n",
       "        [0.73114158, 0.95715809, 0.        ],\n",
       "        [0.69441172, 0.9090025 , 0.18913674],\n",
       "        [0.70994966, 0.93017913, 0.        ],\n",
       "        [0.62632874, 0.84598587, 0.18913674],\n",
       "        [0.71238914, 0.94031853, 0.18913674],\n",
       "        [0.45874073, 0.66812493, 0.18913674],\n",
       "        [0.43745216, 0.62802496, 0.        ],\n",
       "        [0.60732849, 0.76663719, 0.18913674]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X  = preprocessed_X_shuffled[:n_train, :]\n",
    "train_y  = y_shuffled[:n_train] \n",
    "\n",
    "test_X = preprocessed_X_shuffled[n_train:, :]\n",
    "test_y = y_shuffled[n_train:]\n",
    "\n",
    "n_train, train_X, test_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='define_seq_model'></a>2. Define and compile a sequential neural network model with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can start defining the sequential neural network model with `keras.Sequential()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to add a defined number of layers to the sequential model. The procedure is to define three `dense layers`:\n",
    "* Layer 1: `dense layer` with 8 neurons and 3 input dimensions, because the input data has three variables\n",
    "* Layer 2: `dense layer` with 3 neurons\n",
    "* Layer 3: `dense layer` with 1 neuron, because we want to have one output, soil moisture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between the layers, we provide the network with `non-linear properties` by applying an activation function, e.g. `LeakyReLU` or `sigmod` to each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1\n",
    "model.add(Dense(8, input_dim=3))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# Layer 2\n",
    "model.add(Dense(3))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# Layer 3\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is defined, you can compile (configure) the model with `model.compile()` and you can define the following hyperparameters:\n",
    "* `loss='mean_absolute_error'` - MAE is one of many loss options and calculates the distance to the output values which is used to minimize the coefficients\n",
    "* `optimizer=SGD(lr=0.01, momentum=0.9)` - Optimizers are algorithms the network learns from and SGD stands for gradient descent optimizer\n",
    "* `metrics=['mse']` - is used to evaluate how the model is performing\n",
    "\n",
    "<br>\n",
    "\n",
    "**Note related to optimizers:**<br>\n",
    "*During the learning process the network is performing a forward pass which provides the network with an amount to which the coefficients shall be corrected - lr=learning rate. Learning rate and momentum are hyperparameters that can be changed*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error', \n",
    "              optimizer=SGD(lr=0.01, momentum=0.9), \n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='sequential_fitting'></a>3. Training (Fitting) of the sequential model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the data is prepared and the model has been initiated and compiled. The next step is now to train (fit) the model with the defined training data. Before you can start with the model training, it is helpful to define some callbacks that are useful to track model performance and outcomes.\n",
    "\n",
    "We define three callbacks: (i) a `tensorboard`, (ii) an `EarlyStopping` and (iii) a `ModelCheckpoint`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a `tensorboard` is optional, but it is a Tensorflow framework that enables you to easily visualize specific model metrics. You can create a tensorboard with `keras.callbacks.TensorBoard()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful `callback` metric may be `EarlyStopping`, which stops the training if the validation loss (`val_loss`) reaches a minimum (`min`), but waits (`patience`) for 50 epochs.\n",
    "You can define an `EarlyStopping` callback with `keras.callbacks.EarlyStopping()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common callback used is `ModelCheckpoint`, which safes the keras model. During training the `Validation Mean-Squared-Error (MSE)` is monitored and if it reaches a minimum, the model is safed and only the best model fit is kept.\n",
    "\n",
    "You can define a `ModelCheckpoint` callback with `keras.callbacks.ModelCheckpoint()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_mse', mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three callbacks can now be used during the training (fitting) process of the model.\n",
    "You can train (fit) a model in Keras with `model.fit()` and you need to specify the following parameters:\n",
    "* `input (X)` and `output (y)` data: here specify the input and output data of your model\n",
    "* `validation_data`: here we enter the test data subsets test_X and test_y and our model outputs are validated against these validation data after each epoch (training cycle)\n",
    "* `epochs`: number of training cycles\n",
    "* `batch_size`: defines the size of a training data subset (e.g. 10 samples) after which the weights of the network are updated\n",
    "* `callbacks`: define here the callbacks you would like to make use of during the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**<br>\n",
    "*The process where the weights are updated based on the batch_size is also called 'gradient update'.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the training process is a `history` object and for this reason, the output object has the name `history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 3s 67ms/step - loss: 0.2565 - mse: 0.0920 - val_loss: 0.2137 - val_mse: 0.0620\n",
      "\n",
      "Epoch 00001: val_mse improved from inf to 0.06197, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.2079 - mse: 0.0594 - val_loss: 0.2132 - val_mse: 0.0601\n",
      "\n",
      "Epoch 00002: val_mse improved from 0.06197 to 0.06009, saving model to best_model.h5\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.2178 - mse: 0.0613 - val_loss: 0.2135 - val_mse: 0.0602\n",
      "\n",
      "Epoch 00003: val_mse did not improve from 0.06009\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.2124 - mse: 0.0585 - val_loss: 0.2141 - val_mse: 0.0605\n",
      "\n",
      "Epoch 00004: val_mse did not improve from 0.06009\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1914 - mse: 0.0500 - val_loss: 0.2150 - val_mse: 0.0610\n",
      "\n",
      "Epoch 00005: val_mse did not improve from 0.06009\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1952 - mse: 0.0519 - val_loss: 0.2142 - val_mse: 0.0606\n",
      "\n",
      "Epoch 00006: val_mse did not improve from 0.06009\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.2132 - mse: 0.0577 - val_loss: 0.2151 - val_mse: 0.0610\n",
      "\n",
      "Epoch 00007: val_mse did not improve from 0.06009\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.2023 - mse: 0.0555 - val_loss: 0.2149 - val_mse: 0.0609\n",
      "\n",
      "Epoch 00008: val_mse did not improve from 0.06009\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.2000 - mse: 0.0528 - val_loss: 0.2146 - val_mse: 0.0607\n",
      "\n",
      "Epoch 00009: val_mse did not improve from 0.06009\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.2162 - mse: 0.0609 - val_loss: 0.2149 - val_mse: 0.0608\n",
      "\n",
      "Epoch 00010: val_mse did not improve from 0.06009\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.2027 - mse: 0.0555 - val_loss: 0.2145 - val_mse: 0.0606\n",
      "\n",
      "Epoch 00011: val_mse did not improve from 0.06009\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.2052 - mse: 0.0548 - val_loss: 0.2142 - val_mse: 0.0605\n",
      "\n",
      "Epoch 00012: val_mse did not improve from 0.06009\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.2135 - mse: 0.0580 - val_loss: 0.2150 - val_mse: 0.0609\n",
      "\n",
      "Epoch 00013: val_mse did not improve from 0.06009\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.2073 - mse: 0.0579 - val_loss: 0.2143 - val_mse: 0.0606\n",
      "\n",
      "Epoch 00014: val_mse did not improve from 0.06009\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.2030 - mse: 0.0557 - val_loss: 0.2140 - val_mse: 0.0604\n",
      "\n",
      "Epoch 00015: val_mse did not improve from 0.06009\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.2059 - mse: 0.0558 - val_loss: 0.2128 - val_mse: 0.0598\n",
      "\n",
      "Epoch 00016: val_mse improved from 0.06009 to 0.05977, saving model to best_model.h5\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.2023 - mse: 0.0541 - val_loss: 0.2143 - val_mse: 0.0605\n",
      "\n",
      "Epoch 00017: val_mse did not improve from 0.05977\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.1973 - mse: 0.0515 - val_loss: 0.2144 - val_mse: 0.0606\n",
      "\n",
      "Epoch 00018: val_mse did not improve from 0.05977\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.2067 - mse: 0.0551 - val_loss: 0.2137 - val_mse: 0.0602\n",
      "\n",
      "Epoch 00019: val_mse did not improve from 0.05977\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1888 - mse: 0.0496 - val_loss: 0.2140 - val_mse: 0.0604\n",
      "\n",
      "Epoch 00020: val_mse did not improve from 0.05977\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.2072 - mse: 0.0568 - val_loss: 0.2131 - val_mse: 0.0599\n",
      "\n",
      "Epoch 00021: val_mse did not improve from 0.05977\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1906 - mse: 0.0481 - val_loss: 0.2127 - val_mse: 0.0597\n",
      "\n",
      "Epoch 00022: val_mse improved from 0.05977 to 0.05971, saving model to best_model.h5\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1920 - mse: 0.0504 - val_loss: 0.2134 - val_mse: 0.0601\n",
      "\n",
      "Epoch 00023: val_mse did not improve from 0.05971\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1894 - mse: 0.0486 - val_loss: 0.2132 - val_mse: 0.0601\n",
      "\n",
      "Epoch 00024: val_mse did not improve from 0.05971\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1917 - mse: 0.0500 - val_loss: 0.2120 - val_mse: 0.0594\n",
      "\n",
      "Epoch 00025: val_mse improved from 0.05971 to 0.05940, saving model to best_model.h5\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.2030 - mse: 0.0542 - val_loss: 0.2109 - val_mse: 0.0588\n",
      "\n",
      "Epoch 00026: val_mse improved from 0.05940 to 0.05878, saving model to best_model.h5\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1993 - mse: 0.0522 - val_loss: 0.2110 - val_mse: 0.0589\n",
      "\n",
      "Epoch 00027: val_mse did not improve from 0.05878\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1992 - mse: 0.0517 - val_loss: 0.2113 - val_mse: 0.0590\n",
      "\n",
      "Epoch 00028: val_mse did not improve from 0.05878\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1847 - mse: 0.0463 - val_loss: 0.2107 - val_mse: 0.0588\n",
      "\n",
      "Epoch 00029: val_mse improved from 0.05878 to 0.05877, saving model to best_model.h5\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1918 - mse: 0.0477 - val_loss: 0.2114 - val_mse: 0.0592\n",
      "\n",
      "Epoch 00030: val_mse did not improve from 0.05877\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.2107 - mse: 0.0564 - val_loss: 0.2100 - val_mse: 0.0584\n",
      "\n",
      "Epoch 00031: val_mse improved from 0.05877 to 0.05842, saving model to best_model.h5\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1918 - mse: 0.0493 - val_loss: 0.2107 - val_mse: 0.0588\n",
      "\n",
      "Epoch 00032: val_mse did not improve from 0.05842\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1933 - mse: 0.0492 - val_loss: 0.2095 - val_mse: 0.0582\n",
      "\n",
      "Epoch 00033: val_mse improved from 0.05842 to 0.05818, saving model to best_model.h5\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.1885 - mse: 0.0484 - val_loss: 0.2087 - val_mse: 0.0578\n",
      "\n",
      "Epoch 00034: val_mse improved from 0.05818 to 0.05779, saving model to best_model.h5\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1934 - mse: 0.0492 - val_loss: 0.2048 - val_mse: 0.0557\n",
      "\n",
      "Epoch 00035: val_mse improved from 0.05779 to 0.05568, saving model to best_model.h5\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1800 - mse: 0.0436 - val_loss: 0.2010 - val_mse: 0.0532\n",
      "\n",
      "Epoch 00036: val_mse improved from 0.05568 to 0.05324, saving model to best_model.h5\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1937 - mse: 0.0493 - val_loss: 0.2006 - val_mse: 0.0532\n",
      "\n",
      "Epoch 00037: val_mse improved from 0.05324 to 0.05322, saving model to best_model.h5\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.1894 - mse: 0.0473 - val_loss: 0.1996 - val_mse: 0.0525\n",
      "\n",
      "Epoch 00038: val_mse improved from 0.05322 to 0.05250, saving model to best_model.h5\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.1897 - mse: 0.0471 - val_loss: 0.1994 - val_mse: 0.0527\n",
      "\n",
      "Epoch 00039: val_mse did not improve from 0.05250\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1981 - mse: 0.0514 - val_loss: 0.1985 - val_mse: 0.0521\n",
      "\n",
      "Epoch 00040: val_mse improved from 0.05250 to 0.05214, saving model to best_model.h5\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1905 - mse: 0.0481 - val_loss: 0.1982 - val_mse: 0.0522\n",
      "\n",
      "Epoch 00041: val_mse did not improve from 0.05214\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1808 - mse: 0.0418 - val_loss: 0.2005 - val_mse: 0.0543\n",
      "\n",
      "Epoch 00042: val_mse did not improve from 0.05214\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1863 - mse: 0.0447 - val_loss: 0.1958 - val_mse: 0.0503\n",
      "\n",
      "Epoch 00043: val_mse improved from 0.05214 to 0.05032, saving model to best_model.h5\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1872 - mse: 0.0452 - val_loss: 0.1959 - val_mse: 0.0510\n",
      "\n",
      "Epoch 00044: val_mse did not improve from 0.05032\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1862 - mse: 0.0472 - val_loss: 0.1973 - val_mse: 0.0525\n",
      "\n",
      "Epoch 00045: val_mse did not improve from 0.05032\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1898 - mse: 0.0462 - val_loss: 0.1950 - val_mse: 0.0507\n",
      "\n",
      "Epoch 00046: val_mse did not improve from 0.05032\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1928 - mse: 0.0478 - val_loss: 0.1962 - val_mse: 0.0520\n",
      "\n",
      "Epoch 00047: val_mse did not improve from 0.05032\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1777 - mse: 0.0414 - val_loss: 0.1941 - val_mse: 0.0504\n",
      "\n",
      "Epoch 00048: val_mse did not improve from 0.05032\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1751 - mse: 0.0409 - val_loss: 0.1937 - val_mse: 0.0503\n",
      "\n",
      "Epoch 00049: val_mse improved from 0.05032 to 0.05031, saving model to best_model.h5\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1689 - mse: 0.0381 - val_loss: 0.1931 - val_mse: 0.0499\n",
      "\n",
      "Epoch 00050: val_mse improved from 0.05031 to 0.04994, saving model to best_model.h5\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1778 - mse: 0.0410 - val_loss: 0.1933 - val_mse: 0.0506\n",
      "\n",
      "Epoch 00051: val_mse did not improve from 0.04994\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.1683 - mse: 0.0378 - val_loss: 0.1916 - val_mse: 0.0491\n",
      "\n",
      "Epoch 00052: val_mse improved from 0.04994 to 0.04913, saving model to best_model.h5\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1815 - mse: 0.0420 - val_loss: 0.1919 - val_mse: 0.0497\n",
      "\n",
      "Epoch 00053: val_mse did not improve from 0.04913\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.1859 - mse: 0.0445 - val_loss: 0.1901 - val_mse: 0.0483\n",
      "\n",
      "Epoch 00054: val_mse improved from 0.04913 to 0.04830, saving model to best_model.h5\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.1793 - mse: 0.0426 - val_loss: 0.1904 - val_mse: 0.0489\n",
      "\n",
      "Epoch 00055: val_mse did not improve from 0.04830\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.1714 - mse: 0.0388 - val_loss: 0.1894 - val_mse: 0.0484\n",
      "\n",
      "Epoch 00056: val_mse did not improve from 0.04830\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1721 - mse: 0.0382 - val_loss: 0.1914 - val_mse: 0.0502\n",
      "\n",
      "Epoch 00057: val_mse did not improve from 0.04830\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1751 - mse: 0.0415 - val_loss: 0.1892 - val_mse: 0.0486\n",
      "\n",
      "Epoch 00058: val_mse did not improve from 0.04830\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.1646 - mse: 0.0363 - val_loss: 0.1886 - val_mse: 0.0483\n",
      "\n",
      "Epoch 00059: val_mse improved from 0.04830 to 0.04826, saving model to best_model.h5\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.1750 - mse: 0.0406 - val_loss: 0.1911 - val_mse: 0.0502\n",
      "\n",
      "Epoch 00060: val_mse did not improve from 0.04826\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.1749 - mse: 0.0405 - val_loss: 0.1885 - val_mse: 0.0485\n",
      "\n",
      "Epoch 00061: val_mse did not improve from 0.04826\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.1652 - mse: 0.0371 - val_loss: 0.1881 - val_mse: 0.0469\n",
      "\n",
      "Epoch 00062: val_mse improved from 0.04826 to 0.04694, saving model to best_model.h5\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.1725 - mse: 0.0401 - val_loss: 0.1920 - val_mse: 0.0511\n",
      "\n",
      "Epoch 00063: val_mse did not improve from 0.04694\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.1750 - mse: 0.0406 - val_loss: 0.1881 - val_mse: 0.0476\n",
      "\n",
      "Epoch 00064: val_mse did not improve from 0.04694\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.1676 - mse: 0.0379 - val_loss: 0.1879 - val_mse: 0.0473\n",
      "\n",
      "Epoch 00065: val_mse did not improve from 0.04694\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.1600 - mse: 0.0359 - val_loss: 0.1882 - val_mse: 0.0478\n",
      "\n",
      "Epoch 00066: val_mse did not improve from 0.04694\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1691 - mse: 0.0386 - val_loss: 0.1889 - val_mse: 0.0490\n",
      "\n",
      "Epoch 00067: val_mse did not improve from 0.04694\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.1647 - mse: 0.0371 - val_loss: 0.1886 - val_mse: 0.0481\n",
      "\n",
      "Epoch 00068: val_mse did not improve from 0.04694\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.1651 - mse: 0.0382 - val_loss: 0.1888 - val_mse: 0.0483\n",
      "\n",
      "Epoch 00069: val_mse did not improve from 0.04694\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1633 - mse: 0.0356 - val_loss: 0.1912 - val_mse: 0.0513\n",
      "\n",
      "Epoch 00070: val_mse did not improve from 0.04694\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1641 - mse: 0.0369 - val_loss: 0.1885 - val_mse: 0.0479\n",
      "\n",
      "Epoch 00071: val_mse did not improve from 0.04694\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1609 - mse: 0.0355 - val_loss: 0.1894 - val_mse: 0.0497\n",
      "\n",
      "Epoch 00072: val_mse did not improve from 0.04694\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1610 - mse: 0.0365 - val_loss: 0.1893 - val_mse: 0.0493\n",
      "\n",
      "Epoch 00073: val_mse did not improve from 0.04694\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1701 - mse: 0.0404 - val_loss: 0.1884 - val_mse: 0.0478\n",
      "\n",
      "Epoch 00074: val_mse did not improve from 0.04694\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1631 - mse: 0.0380 - val_loss: 0.1913 - val_mse: 0.0516\n",
      "\n",
      "Epoch 00075: val_mse did not improve from 0.04694\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1676 - mse: 0.0414 - val_loss: 0.1897 - val_mse: 0.0494\n",
      "\n",
      "Epoch 00076: val_mse did not improve from 0.04694\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1595 - mse: 0.0345 - val_loss: 0.1902 - val_mse: 0.0502\n",
      "\n",
      "Epoch 00077: val_mse did not improve from 0.04694\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1670 - mse: 0.0381 - val_loss: 0.1923 - val_mse: 0.0525\n",
      "\n",
      "Epoch 00078: val_mse did not improve from 0.04694\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1512 - mse: 0.0333 - val_loss: 0.1889 - val_mse: 0.0486\n",
      "\n",
      "Epoch 00079: val_mse did not improve from 0.04694\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1600 - mse: 0.0385 - val_loss: 0.1919 - val_mse: 0.0521\n",
      "\n",
      "Epoch 00080: val_mse did not improve from 0.04694\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1650 - mse: 0.0392 - val_loss: 0.1918 - val_mse: 0.0519\n",
      "\n",
      "Epoch 00081: val_mse did not improve from 0.04694\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1652 - mse: 0.0408 - val_loss: 0.1893 - val_mse: 0.0490\n",
      "\n",
      "Epoch 00082: val_mse did not improve from 0.04694\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1551 - mse: 0.0355 - val_loss: 0.1907 - val_mse: 0.0506\n",
      "\n",
      "Epoch 00083: val_mse did not improve from 0.04694\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1628 - mse: 0.0382 - val_loss: 0.1973 - val_mse: 0.0574\n",
      "\n",
      "Epoch 00084: val_mse did not improve from 0.04694\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1724 - mse: 0.0433 - val_loss: 0.1896 - val_mse: 0.0494\n",
      "\n",
      "Epoch 00085: val_mse did not improve from 0.04694\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1622 - mse: 0.0363 - val_loss: 0.1905 - val_mse: 0.0506\n",
      "\n",
      "Epoch 00086: val_mse did not improve from 0.04694\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.1455 - mse: 0.0330 - val_loss: 0.1982 - val_mse: 0.0582\n",
      "\n",
      "Epoch 00087: val_mse did not improve from 0.04694\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.1587 - mse: 0.0368 - val_loss: 0.1890 - val_mse: 0.0491\n",
      "\n",
      "Epoch 00088: val_mse did not improve from 0.04694\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.1603 - mse: 0.0370 - val_loss: 0.1895 - val_mse: 0.0496\n",
      "\n",
      "Epoch 00089: val_mse did not improve from 0.04694\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.1606 - mse: 0.0367 - val_loss: 0.1958 - val_mse: 0.0563\n",
      "\n",
      "Epoch 00090: val_mse did not improve from 0.04694\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1770 - mse: 0.0462 - val_loss: 0.1906 - val_mse: 0.0507\n",
      "\n",
      "Epoch 00091: val_mse did not improve from 0.04694\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1640 - mse: 0.0398 - val_loss: 0.1908 - val_mse: 0.0511\n",
      "\n",
      "Epoch 00092: val_mse did not improve from 0.04694\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1630 - mse: 0.0400 - val_loss: 0.1900 - val_mse: 0.0502\n",
      "\n",
      "Epoch 00093: val_mse did not improve from 0.04694\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1673 - mse: 0.0426 - val_loss: 0.1894 - val_mse: 0.0498\n",
      "\n",
      "Epoch 00094: val_mse did not improve from 0.04694\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1788 - mse: 0.0455 - val_loss: 0.1967 - val_mse: 0.0572\n",
      "\n",
      "Epoch 00095: val_mse did not improve from 0.04694\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1527 - mse: 0.0373 - val_loss: 0.1896 - val_mse: 0.0505\n",
      "\n",
      "Epoch 00096: val_mse did not improve from 0.04694\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1764 - mse: 0.0450 - val_loss: 0.2022 - val_mse: 0.0620\n",
      "\n",
      "Epoch 00097: val_mse did not improve from 0.04694\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1488 - mse: 0.0330 - val_loss: 0.1888 - val_mse: 0.0494\n",
      "\n",
      "Epoch 00098: val_mse did not improve from 0.04694\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1705 - mse: 0.0434 - val_loss: 0.1894 - val_mse: 0.0500\n",
      "\n",
      "Epoch 00099: val_mse did not improve from 0.04694\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.1500 - mse: 0.0336 - val_loss: 0.1888 - val_mse: 0.0494\n",
      "\n",
      "Epoch 00100: val_mse did not improve from 0.04694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fba7423c250>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(train_X, train_y, \n",
    "                    validation_data=(test_X, test_y), \n",
    "                    epochs=100, \n",
    "                    batch_size=10,\n",
    "                    callbacks=[tensorboard_callback, es, mc])\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='model_evaluation'></a>4. Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training process, you want to evaluate the performance of the model. Since we defined the `ModelCheckpoint` callback, you can load the output of the `ModelCheckPoint` with `keras.models.load_model()`. Note that the output is different to the `history` object during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fba741d8730>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('./best_model.h5')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `model.evaluate()` you can evaluate the model predictions based on the test data subsets for X (`test_X`) and y (`test_y`) we have created before. The output returns the mean-squared-error (MSE) between predictions and test data. The aim is to optimize (minimize) the `MSE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1881 - mse: 0.0469\n",
      "Mse: 0.0469\n"
     ]
    }
   ],
   "source": [
    "_, test_mse = model.evaluate(test_X, test_y)\n",
    "\n",
    "print('Mse: %.4f' % test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful evaluation is to plot the `loss` and `validation_loss` metrics during training:\n",
    "* `loss`: mean absolute error during training (blue line)\n",
    "* `validation_loss`: mean absolute error while validating the training outputs with test data (orange line)\n",
    "\n",
    "Both lines (blue and orange) show a decreasing trend during the training process, which indicates a successful training process. The decreasing trend of the orange line shows also that the model is capable of decreasing the mean absolute error when validated with test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fba6c6a8eb0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'], label='MAE - training')\n",
    "pyplot.plot(history.history['val_loss'], label='MAE - validation with test data')\n",
    "pyplot.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='soil_moisture_prediction'></a>5. Predicting soil moisture with the trained sequential neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, you can now use the trained sequential neural network and predict soil moisture, based on the test input `test_X_S1`, which has `SAR VH and VV backscattering values in db` and `incidence angle in degrees` of four Sentinel-1 samples.\n",
    "\n",
    "The code below goes through the four samples of the test input variable and based on the trained model, predicts the soil moisture based on the Sentinel-1 samples. The prediction is done with the function `model.predict()`. The predicted soil moisture values are stored in a list (`predicted`).\n",
    "\n",
    "At the end, the input and output soil moisture values are printed together with the predicted soil moisture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input values: [1.         0.78706989 0.02841644],  Output soil moisture: 0.0848\n",
      "Predicted soil moisture: [[0.4584852]]\n",
      " \n",
      "Input values: [0.97094106 0.61020754 0.02974598],  Output soil moisture: 0.1534\n",
      "Predicted soil moisture: [[0.34718686]]\n",
      " \n",
      "Input values: [0.99969916 0.61815558 0.0318183 ],  Output soil moisture: 0.1139\n",
      "Predicted soil moisture: [[0.35440984]]\n",
      " \n",
      "Input values: [0.96187422 0.65006854 1.        ],  Output soil moisture: 0.106\n",
      "Predicted soil moisture: [[0.47349933]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for index, value in enumerate(test_X_S1):\n",
    "    pred = np.expand_dims(value, axis=0)\n",
    "    predicted.append(model.predict(pred))\n",
    "    \n",
    "    print(\"Input values: \" + str(value) + \",  Output soil moisture: \" + str(test_y_S1[index]))\n",
    "    print(\"Predicted soil moisture: \" + str(model.predict(pred)) + \"\\n \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='evaluate_soil_moisutre_pred'></a> Evaluate model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common tool to evaluate the accuracy of predicted values versus validation values is the visualisation of both as a scatter plot. Such a scatter plot shows the `original vs the predicted` soil moisture values as scatters. It a great graphical representation showing whether the trained sequential neural network model has a tendency to over- or underpredict `soil moisture information`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result below shows you that the trained model has a tendency to over-predict soil moisture values.\n",
    "\n",
    "**Note**: for more accurate results, you would need more than only four point locations to evaluate the predicted values against. Further, you can modify the hyperparameters in order to improve the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predicted')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = pyplot.subplots()\n",
    "ax.scatter(test_y_S1, predicted)\n",
    "ax.plot([test_y.min(), test_y.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Original')\n",
    "ax.set_ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, you can calculate the `Pearson correlation coefficient` between original (to-predict) and predicted soil moisture values. The coefficient value can range between `[-1,1]` and is a measure about the strength of the correlation between original and predicted soil moisture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: -0.763\n"
     ]
    }
   ],
   "source": [
    "test_y_nparray = np.array(test_y_S1)\n",
    "test_y_flattened = test_y_nparray.flatten()\n",
    "predicted_nparray = np.array(predicted)\n",
    "predicted_flattened = predicted_nparray.flatten()\n",
    "\n",
    "corr, _ = scipy.stats.pearsonr(test_y_flattened, predicted_flattened)\n",
    "print('Pearson correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.futurelearn.com/courses/artificial-intelligence-for-earth-monitoring/1/steps/1170987\"><< Back to FutureLearn</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../../img/copernicus_logo.png' alt='Copernicus logo' align='left' width='20%'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Course developed for [EUMETSAT](https://www.eumetsat.int/), [ECMWF](https://www.ecmwf.int/) and [Mercator Ocean International](https://www.mercator-ocean.fr/en/) in support of the [EUs Copernicus Programme](https://www.copernicus.eu/en) and the [WEkEO platform](https://wekeo.eu/).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
 "tags": {
"domain": "Machine Learning",
"category": "training",
"algorithm": "Neural network",
"framework": "Keras",
"data": "SAR backscatter and incidence angle information"
},
  "title": "Training of a sequential neural network for soil moisture prediction",
  "description": "This workflow will guide you through the different steps to train asequential neural network modelin order to predict soil moisture based on SAR backscatter and incidence angle information.",
  "image": "./img_13.png",
  "link": "https://jupyterhub-wekeo.apps.eumetsat.dpi.wekeo.eu/hub/user-redirect/lab/tree/public/ML/3_land/3D1_soil_moisture_estimation/3D_soil_moisture_estimation.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
